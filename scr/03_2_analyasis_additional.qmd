---
title: "03_2_analysis_additional"
format: md
editor: visual
---

## Additional tests for FV fragments

```{r, warning=FALSE, message=FALSE}
library(tidyverse)
library(tidytext)
library(stylo)
library(seetrees)
library(tinytex)

theme_set(theme_minimal())
library(MetBrewer)
```

Load data

```{r}
corpus <- readRDS("../data/corpus_cln.Rds")

unique(corpus$author)

corpus_tokenized <- corpus %>% 
  mutate(author = ifelse(author == "d", "dHolbach", author)) %>% 
  # remove old texts in question
  filter(!author %in% c("H-FP", "FP II (old version of FP)",
                        "H-V-FP", "V-FP", "HDI(clean)",
                        "Marmontel"))

glimpse(corpus_tokenized)

# total number of tokens by each author, two samples from Diderot
corpus_tokenized %>% 
  count(author, sort = T) 

rm(corpus)
```

Test fragments

```{r}
rchina <- tibble(
  path = "../corpus_fragments/test_fragments/fr_on_russia-china.txt",
  title = "fr_russia_china",
  author = "fr_russia_china",
  text = read_file(path)
) %>% 
  unnest_tokens(input = text, output = word, token = "words")

sauvage <- tibble(
  path = "../corpus_fragments/test_fragments/fr_sauvage.txt",
  title = "fr_la vie sauvage",
  author = "fr_la vie sauvage",
  text = read_file(path)
) %>% 
  unnest_tokens(input = text, output = word, token = "words")

ink_only <- tibble(
  path = "../corpus_fragments/test_fragments/ink_melanges_not-in-pencil.txt",
  title = "ink_mélanges_only",
  author = "ink_mélanges_only",
  text = read_file(path)
) %>% 
  unnest_tokens(input = text, output = word, token = "words")
```

### fn

```{r}
sample_independent_opt <- function(tokenized_df,
  n_samples,
  sample_size,
  text_var = "word",
  folder = "corpus_sampled/", overwrite=T) {


  # create a folder
  dir.create(folder)
  
  # rewrite all files in the folder if the folder existed before
  if(overwrite) {
    do.call(file.remove, list(list.files(folder, full.names = TRUE)))
  }
  
  shuff <- tokenized_df %>%
    group_by(author) %>%
    sample_n(n_samples * sample_size) %>% # sample tokens
    # to each sampled token assign randomly a sample number
    mutate(sample_x = sample( # sample = reshuffle the numbers of samples repeated below
    rep( # repeat
      1:n_samples, # the numbers of samples (1, 2, 3...)
      each = sample_size # each is sample_size times repeated
      ))) %>%
    # create a column author_sampleX
    unite(sample_id, c(author, sample_x), remove = F) %>%
    # group and paste together by sample_id (some kind of special paste with !!sym() )
    group_by(sample_id) %>%
    summarise(text = paste(!!sym(text_var), collapse = " "))
    
    # write samples
    for(i in 1:nrow(shuff)) {
    write_file(file=paste0(folder, shuff$sample_id[i],".txt"), shuff$text[i])
  }
}
```

```{r}
diy_stylo <- function(folder = "corpus_sampled/",
                      mfw = 200,
                      drop_words = T,
                      feature = "word",
                      n_gram = 1) {
  
  # read the sampled texts from the folder corpus_sampled/
  # the feature is either word or charaters
  # the tokenizer returns lists of tokens for each text from the folder
  tokenized.texts = load.corpus.and.parse(
    files = list.files(folder, full.names = T),
    features = feature,
    ngram.size = n_gram
  )
  # computing a list of most frequent words (trimmed to top 2000 items):
  features = make.frequency.list(tokenized.texts, head = 2000)
  # producing a table of relative frequencies:
  data = make.table.of.frequencies(tokenized.texts, features, relative = TRUE)#[,1:mfw]
  
  
  
  # --- cleaning ---
  # remove stop words
  s_words <- str_detect(colnames(data), str_dev_words) # output is a logical vector with the positions of the 
  if(drop_words) {
    data <- data[,!s_words]
  }
  # crop mfw
  data <- data[, 1:mfw]
  # clean document names
  
  rownames(data) <- str_remove_all(rownames(data), "corpus_sampled/") # Clean Rownammes
  rownames(data) <- str_remove_all(rownames(data), "^.*?//") # clean rownames from full paths
  
  
  # output
  return(data)
}
```

## Fragments on China & Russia

```{r}
china_r_corpus <- rbind(rchina, corpus_tokenized)
```

```{r}
sample_independent_opt(tokenized_df = china_r_corpus,
  n_samples = 2,
  sample_size = 2600)
```

### stylo test

```{r, message=FALSE, warning=FALSE}
test1 <- stylo(
  gui = F,
  corpus.dir = "corpus_sampled/",
  corpus.lang = "French",
  mfw.min = 200,
  mfw.max = 200,
  analyzed.features = "w",
  ngram.size = 1,
  distance.measure = "wurzburg"
  )
```

### mfw200

```{r}
test1$features.actually.used
```

### BCT

```{r, message=FALSE, warning=FALSE}
# bootstrap consensus tree
bct <- stylo(
  gui = F,
  corpus.dir = "corpus_sampled/",
  corpus.lang = "French",
  analyzed.features = "w",
  ngram.size = 1,
  mfw.min = 50,
  mfw.max = 250,
  mfw.incr = 1,
  distance.measure = "wurzburg",
  analysis.type = "BCT",
  consensus.strength = 0.5
)
```

### Imposters

```{r}
# var needed for diy fn
str_dev_words <- c("et")
```

```{r, message=FALSE, warning=FALSE, eval=FALSE, include=FALSE}
sample_independent_opt(tokenized_df = china_r_corpus,
  n_samples = 2,
  sample_size = 2600)

dtm <- diy_stylo(
  folder = "corpus_sampled/",
  mfw = 200,
  drop_words = F)

grep("fr_", rownames(dtm))
```

```{r, message=FALSE, warning=FALSE, eval=FALSE}
imp_res <- vector(mode = "list")

counter <- 0

for (i in 1:50) {
  
  # create samples for each trial
  sample_independent_opt(
    tokenized_df = china_r_corpus, 
    n_samples = 2, 
    sample_size = 2500)
  
  # build doc-term matrix from the samples in the corpus_sampled folder
  data = diy_stylo(mfw = 200, 
                    feature = "word",
                    n_gram = 1)
  
  # test each of the true FV-L1 sets
  for (s in c(15, 16)) {
    
    # run imposters test
    r <- imposters(reference.set = data[-c(15, 16),], # remove test data from the ref
                   test = data[c(s),], # test one of the samples against the others
                   features = 0.5, # test 50% of the features in each trial
                   iterations = 100,
                   distance = "wurzburg"
                   )
    
    # count iterations
    counter <- counter + 1
    
    # store results
    
    imp_res[[counter]] <- tibble(candidate = names(r),
                                 proportion = r)
    
    print(counter)
  }
  
}

saveRDS(imp_res, "imp_res/impr_fr_china-russia.rds")
```

```{r}
imp_res <- readRDS("imp_res/impr_fr_china-russia.rds")

imp_res %>%
  bind_rows() %>%  #stack all the optained prop tables into one
  ggplot(aes(x = reorder(candidate, - proportion),
  y = proportion)) +
  geom_boxplot() +
  theme_bw() + 
  labs(subtitle = "Proportion of cases where a sample from an author was the closest one\nto the fragments on Russia (68, 310) and China (12)") +
  theme(axis.text.x = element_text(angle = 25))
```

## Framgent 'Les avantages de la vie sauvage'

```{r}
sauvage_corpus <- rbind(sauvage, corpus_tokenized) %>% 
  mutate(author = ifelse(author == "Diderot II", "Diderot", author))
```

```{r}
sample_independent_opt(tokenized_df = sauvage_corpus,
  n_samples = 2,
  sample_size = 4000)
```

### stylo test

```{r, message=FALSE, warning=FALSE}
test1 <- stylo(
  gui = F,
  corpus.dir = "corpus_sampled/",
  corpus.lang = "French",
  mfw.min = 200,
  mfw.max = 200,
  analyzed.features = "w",
  ngram.size = 1,
  distance.measure = "wurzburg"
  )
```

### mfw200

```{r}
test1$features.actually.used
```

### BCT

```{r, message=FALSE, warning=FALSE}
# bootstrap consensus tree
bct <- stylo(
  gui = F,
  corpus.dir = "corpus_sampled/",
  corpus.lang = "French",
  analyzed.features = "w",
  ngram.size = 1,
  mfw.min = 50,
  mfw.max = 450,
  mfw.incr = 1,
  distance.measure = "wurzburg",
  analysis.type = "BCT",
  consensus.strength = 0.5
)
```

### Imposters

```{r, message=FALSE, warning=FALSE, eval=FALSE, include=FALSE}
sample_independent_opt(tokenized_df = sauvage_corpus,
  n_samples = 2,
  sample_size = 4000)

dtm <- diy_stylo(
  folder = "corpus_sampled/",
  mfw = 200,
  drop_words = F)

grep("fr_", rownames(dtm))
```

```{r, message=FALSE, warning=FALSE, eval=FALSE}
imp_res <- vector(mode = "list")

counter <- 0

for (i in 1:50) {
  
  # create samples for each trial
  sample_independent_opt(
    tokenized_df = sauvage_corpus, 
    n_samples = 2, 
    sample_size = 4000)
  
  # build doc-term matrix from the samples in the corpus_sampled folder
  data = diy_stylo(mfw = 200, 
                    feature = "word",
                    n_gram = 1)
  
  # test each of the true FV-L1 sets
  for (s in c(13, 14)) {
    
    # run imposters test
    r <- imposters(reference.set = data[-c(13, 14),], # remove test data from the ref
                   test = data[c(s),], # test one of the samples against the others
                   features = 0.5, # test 50% of the features in each trial
                   iterations = 100,
                   distance = "wurzburg"
                   )
    
    # count iterations
    counter <- counter + 1
    
    # store results
    
    imp_res[[counter]] <- tibble(candidate = names(r),
                                 proportion = r)
    
    print(counter)
  }
  
}

saveRDS(imp_res, "imp_res/impr_fr_la-vie-sauvage_2.rds")
```

```{r}
imp_res <- readRDS("imp_res/impr_fr_la-vie-sauvage_2.rds")

imp_res %>%
  bind_rows() %>%  #stack all the optained prop tables into one
  ggplot(aes(x = reorder(candidate, - proportion),
  y = proportion)) +
  geom_boxplot() +
  theme_bw() + 
  labs(subtitle = "Proportion of cases where a sample from an author was the closest one\nto the fragment 'Les avantages de la vie sauvage'") +
  theme(axis.text.x = element_text(angle = 25, size = 12))
```

## Ink selection: fragments, appeared only in Mélanges

N words = 37 580

```{r}
ink_selection_corpus <- rbind(ink_only, corpus_tokenized)
```

```{r}
sample_independent_opt(tokenized_df = ink_selection_corpus,
  n_samples = 2,
  sample_size = 5000)
```

### stylo test

```{r, message=FALSE, warning=FALSE}
test1 <- stylo(
  gui = F,
  corpus.dir = "corpus_sampled/",
  corpus.lang = "French",
  mfw.min = 200,
  mfw.max = 200,
  analyzed.features = "w",
  ngram.size = 1,
  distance.measure = "wurzburg"
  )
```

```{r}
test1$features.actually.used
```

### BCT

```{r, message=FALSE, warning=FALSE}
# bootstrap consensus tree
bct <- stylo(
  gui = F,
  corpus.dir = "corpus_sampled/",
  corpus.lang = "French",
  analyzed.features = "w",
  ngram.size = 1,
  mfw.min = 50,
  mfw.max = 250,
  mfw.incr = 1,
  distance.measure = "wurzburg",
  analysis.type = "BCT",
  consensus.strength = 0.5
)
```

### Imposters

```{r, message=FALSE, warning=FALSE, eval=FALSE, include=FALSE}
sample_independent_opt(tokenized_df = ink_selection_corpus,
  n_samples = 2,
  sample_size = 5000)

dtm <- diy_stylo(
  folder = "corpus_sampled/",
  mfw = 200,
  drop_words = F)

grep("ink_mélanges_only", rownames(dtm))
```

```{r, message=FALSE, warning=FALSE, eval=FALSE}
imp_res <- vector(mode = "list")

counter <- 0

for (i in 1:50) {
  
  # create samples for each trial
  sample_independent_opt(
    tokenized_df = ink_selection_corpus, 
    n_samples = 2, 
    sample_size = 5000)
  
  # build doc-term matrix from the samples in the corpus_sampled folder
  data = diy_stylo(mfw = 200, 
                    feature = "word",
                    n_gram = 1)
  
  # test each of the true FV-L1 sets
  for (s in c(17, 18)) {
    
    # run imposters test
    r <- imposters(reference.set = data[-c(17, 18),], # remove test data from the ref
                   test = data[c(s),], # test one of the samples against the others
                   features = 0.5, # test 50% of the features in each trial
                   iterations = 100,
                   distance = "wurzburg"
                   )
    
    # count iterations
    counter <- counter + 1
    
    # store results
    
    imp_res[[counter]] <- tibble(candidate = names(r),
                                 proportion = r)
    
    print(counter)
  }
  
}

saveRDS(imp_res, "imp_res/impr_ink_only_selection.rds")
```

```{r}
imp_res <- readRDS("imp_res/impr_ink_only_selection.rds")

imp_res %>%
  bind_rows() %>%  #stack all the optained prop tables into one
  ggplot(aes(x = reorder(candidate, - proportion),
  y = proportion)) +
  geom_boxplot() +
  theme_bw() + 
  labs(subtitle = "Proportion of cases where a sample from an author was the closest one\nto the selection of fragments from Mélanges (fragments not included in PD)") +
  theme(axis.text.x = element_text(angle = 25))
```

nb don't forget to count CI for selected imposters plots
